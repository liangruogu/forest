---
title: 建立起对高斯分布的直觉
published: 2024-11-28
updated: 2024-11-28
description: "在学习概率论时，这些问题困扰了我很久--为什么高斯分布是这样的？为什么在任何地方都可以假设误差或者某一个分布服从高斯分布，而且还会比较贴合？这些问题困扰着我，所以我学习很多额外的知识，并将它记录了下来"
image: ''
tags: ["math", "python"]
category: 'math'
draft: false 
---




## 前提须知

下面的文字将泰勒展开、傅里叶展开进行类比，欧拉公式作为桥梁旨在建立良好的直觉，为了足够直观，忽略了很多作为支撑的定理。也希望你能感受到数学的美



实数域上，我们使用幂级数，$x$, $x^2$ 等等这些来拟合函数，因为他们足够简单，本身和导数都足够简单

在复数域上的计算经常会涉及到旋转，角度这些，如果再使用幂级数，那在展开某一个n次方的复数时，它变得非常复杂

我们经常使用 $sin$ 和 $cos$ 来表示复数，也就是复数的三角形式。这样在进行复数的乘法上，我们只需要将辐角相加，模长相乘即可，所以我们可以建立一个意识--在复数域上 $sin$ 和 $cos$ 更简单。所以我们也可以尝试使用二者来拟合函数

考虑到sin和cos本身就是周期函数，所以它们在拟合周期函数上就有天生的优势。其实 sin 和 cos本身就会存在很强的关系

$cos(x)$ 经过平移以后就可以变成$sin(x)$ 它经常是 $\frac{\pi}{2}$ 的倍数 如果我们把$\frac{\pi}{2}$作为辐角，会得到最简单的纯虚数--i，那这三者是否会存在某种特殊的关系呢？

让我们接着往下看：





### 泰勒展开

所以对于任何一个函数,我们可以使用这样的幂级数来拟合它
$$
f(x) = \sum\limits_{i=0}^{+\infty}a_{i}x^i \tag{1.1.1}
$$
那我们应该如何计算这些系数呢？仔细思考拟合，我们拟合的是什么？在某一个点的值相等，那就会在这个点上表现很好，那如果是一个区域呢？每一个区域内都有无限个点，那其实我就可以有无限的方程，但是它们真的有意义吗？

在生活中我们模仿一个人，不只是模仿他当前的状态，我们可能会去看他动的趋势，在数学上也就是拟合他的变化趋势也就是导数，所以如果在某一点的导数相等那也是比较好的。那我们就找到了思路，通过对$f(x)$不断求导来构建等式，这样就可以求解出系数$a_i$

最后得到的也就是这个函数的泰勒展开了，常见的
$$
sin(x) = \sum\limits_{n=0}^{+\infty}\frac{(-1)^{n}x^{2n+1}}{(2n+1)!}  \tag{1.1.2}
$$

$$
cos(x) = \sum\limits_{n=0}^{+\infty}\frac{(-1)^nx^{2n}}{(2n)!}  \tag{1.1.3}
$$

$$
e^x = \sum\limits_{n=0}^{+\infty}\frac{x^n}{n!}  \tag{1.1.4}
$$



### 欧拉公式

如果你知道欧拉公式
$$
e^{i\theta} = cos(\theta) + isin(\theta) \tag{1.2.1}
$$
我们就可以观察到一些有意思的东西了，结合(1.1.2),(1.1.3),(1.1.4)就可以推出(1.2.1)

而且它刚好由这几个部分组成 $e \space cos \space sin \space i$ ! !  

这个等式很好的印证了我们的猜想--$cos \space sin \space i$ 之间是否存在某种关系。

另外，这个公式也可以很好解释复数的乘法，因为指数相乘的会体现为相加，也就对应于辐角的相加了。



### 傅里叶展开

接下来我们看看复数域上的“泰勒展开”，我们使用$sin \space cos$ 来拟合函数

$$
f(x) = \sum\limits_{n=0}^{+\infty}a_ncos(\frac{2\pi nx}{T})+b_nsin(\frac{2\pi nx}{T}) \tag{1.3.1}
$$
那我们应该如何求解系数呢？我们是否可以像在实数域上一样对两边求导呢？很明显不行，因为sin和cos都是周期函数，其导数也是周期函数，重要的并不是函数的变化趋势。思考区分每个系数的是什么？是后面的sin和cos以及里面的n，所以要根据这些和具体的$f(x)$来确定系数。那到底区别在哪里呢？频率。就是频率，n决定函数周期。这么多的频率相加，我又应该如何分解出我想要的某一个频率呢？

思考我们在一个空间中是如何区分向量的？两个向量之所以不同是因为它们在同一组基下的某个方向上的坐标不同，类比到这里。我们需要构建一组"基底"，基底的定义中有正交，所以我们需要定义内积，看看这里我们是否可以选则$cos(x)和sin(x)$作为基底呢？

那我们如何定义内积呢？内积需要满足三个性质，线性性，对称性，正定性。这是用集合论的方式描述的，为了维护直观，我直接给出这里的定义
$$
(f, g) = \int_a^b f(x)g(x)dx \tag{1.3.2}
$$
我们很容易验证这三条性质。什么是正交？正交是内积为零，也就是二者乘积的积分为零，在这里我们可以使用证明不同频率的正弦波和余弦波是正交的，也就是
$$
\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} cos(nx)sin(mx) = 0, \space \space \space \forall n,m  \tag{1.3.3}
$$

$$
\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}cos(nx)cos(mx) = 0  \space \space \space (n\not=m) \tag{1.3.4}
$$

$$
\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}sin(nx)sin(mx) = 0 \space \space \space (n\not=m) \tag{1.3.5}
$$



这样我们就可以区分开不同的项了，也就可以计算对应的系数了。我们对(1.6)式左右同时和 $sin(\frac{2n\pi x}{T})$ 在一个周期内做内积，cos项都会变成0，sin项也只会剩下一项
$$
\int_{0}^{T}f(x)sin(\frac{2n\pi x}{T})dx = \int_{0}^{T}b_nsin^2(\frac{2n\pi x}{T})dx \tag{1.3.6}
$$
容易计算
$$
\int_0^Tb_nsin^2(\frac{2n\pi x}{T})dx = \frac{T}{2} \tag{1.3.7}
$$
所以
$$
b_n = \frac{2}{T}\int_0^Tf(x)sin(\frac{2n\pi x}{T})dx \tag{1.3.8}
$$
同理可得
$$
a_n = \frac{2}{T}\int_0^Tf(x)cos(\frac{2n\pi x}{T})dx \tag{1.3.9}
$$
这样我们就可以计算出对函数$f(x)$展开的系数了，我们是利用不同频率的波是正交的等特性分解出了每一项，从而计算出它们的系数的，反过来说的话其实就是：我们使用傅里叶级数区提取出了不同频率的波。



### 傅里叶级数的指数形式

如果我们将(1.3.1)式中的三角函数换成e的指数幂，也就是使用欧拉公式对它进行化简，就可以得到$f(x)$的另一种傅里叶级数的形式，这里直接给出结果
$$
f(x) = \sum\limits_{n=-\infty}^{+\infty}c_ne^{in\omega_0 t} \tag{1.4.1}
$$

$$
c_n = \frac{1}{T}\int_{0}^{T}f(t)e^{-in\omega_0 t}dt \tag{1.4.2}
$$

其中

$\omega_0 = \frac{2\pi}{T}$

$c_n = \frac{a_n - ib_n}{2}$ for $n \geqslant 1$

$c_{-n} = \frac{a_n + ib_n}{2}$ for $n \geqslant 1$

$c_0 = a_0$

## 中心极限定理

### 定理介绍

设随机变量$X_1,X_2,\dots,X_n,\dots$ 相互独立，服从同一分布，且具有数学期望和方差:$E(X_k) = \mu, D(X_k) = \sigma^2 > 0 \space (k=1,2\dots)$,则随机变量之和$\sum\limits_{k=1}^{n}X_k$的标准化变量
$$
Y_n = \frac{\sum\limits_{k=1}^n{X_k} - E(\sum\limits_{k=1}^{n}X_k)}{\sqrt{D(\sum\limits_{k=1}^{n}X_k)}} = \frac{\sum\limits_{k=1}^{n}X_k - n\mu}{\sqrt{n}\sigma} \tag{2.1}
$$
的分布函数$F_n(x)$对于任意$x$ 满足
$$
\lim_{n \to \infty}F_n(x) = \lim_{n \to \infty}P(\frac{\sum\limits_{k=1}^{n}X_k - n\mu}{\sqrt{n}\sigma} \leqslant x ) \\
\quad\quad\quad\quad \space
=\int_{-\infty}^{x}\frac{1}{\sqrt{2\pi}}e^{-t^2/2}dt = \Phi(x)
$$
这是浙大概率论课本上给出的独立同分布的中心极限定理，大概意思就是：对如果多个独立同分布的随机变量进行卷积，最后就可以得到一个近似服从高斯分布的随机变量，即
$$
\frac{\sum\limits_{k=1}^{n}X_k - n\mu}{\sqrt{n}\sigma} \sim N(0,1)
$$

### 定理验证（可视化）

我使用python对服从参数$\lambda=5$泊松分布总体X进行简单随机抽样，得到了样本$X_1, X_2 \dots X_{1000}$

接着画出了
$$
Y = \sum\limits_{n=1}^{1000}X_n
$$
的分布，得到了下图、

<img src="https://raw.githubusercontent.com/liangruogu/BlogImages/main/img/泊松分布.png">

结果也是不出意料，非常接近正态分布，我接着对服从均匀分布的总体进行抽样再将得到的样本进行卷积，得到了下面的图像。

<img src="https://raw.githubusercontent.com/liangruogu/BlogImages/main/img/均匀分布.png">

我们现在也就可以很直观的感受到了：无论一个随机变量无论它一开始服从什么分布，只要我们将它对自己进行足够次数的卷积，它最后会变得非常像高斯分布。



### 随机变量与傅里叶变换

#### 变量卷积

正常的对两个独立同分布的随机变量进行卷积是下面的公式
$$
f_Y(y) = \int_{-\infty}^{+\infty}f(x)f(y-x)dx \tag{2.3.1}
$$
但是当卷积的数量很多时
$$
f_Y(y) = f_1*f_2\cdots*f_n \tag{2.3.2}
$$
我们并没有什么快速的方法计算它，只能一次次的将两个随机变量进行卷积，这样的计算成本必然是我们无法承受的。是否有更便捷的方法？

这里的计算复杂是因为函数相乘和积分是交替进行的，那么我们是否可以让$f(x)$先变换成某一种形式，让(2.3.2)式化简之后再将结果逆变换回来呢？

#### 傅里叶变换

数学家们给出的答案是傅里叶变换
$$
F(\omega) = \int_{-\infty}^{+\infty}f(t)e^{-i\omega t}dt \tag{2.3.3}
$$
我们从整体来把握，傅里叶变换是将一个实变函数$f(t)$映射到了一个复变函数$F(\omega)$

傅里叶变换有下面这些良好的性质

1. 它是线性的
2. 在一定条件下，它是一一映射的（可逆）
3. 时移性质、频移性质等等

最最重要的是，它非常擅长化简卷积
$$
\mathcal{F}[f(t)*g(t)] = G(\omega)F(\omega) \tag{2.3.4}
$$
其中$G,F$分别为$f,g$的傅里叶变换的结果，我们可以对(2.3.3)进行推广，得到
$$
\mathcal{F}[f_1*f_2\cdots*f_n] = F_1(\omega)F_2(\omega)\cdots F_n(\omega) \tag{2.3.5}
$$
特别地,
$$
\mathcal{F}[f*f\cdots*f] = F^{n}(\omega) \tag{2.3.6}
$$
这样我们就可以很好的化简(2.3.2)式了，
$$
\mathcal{F}[f_Y(y)] = \mathcal{F}[f*f*\cdots *f] = F^n(\omega) \tag{2.3.7}
$$
这个时候如果我们想得到$f_Y(y)$,只需要对(2.3.6)式左右同时进行傅里叶逆变换就可以了
$$
f_Y(y) = \mathcal{F}^{-1}\big[{F}^{n}(\omega)\big] \tag{2.3.8}
$$

#### 特征函数与矩

随机变量$X$的特特征函数:
$$
\phi(t)= E[e^{-itX}] = \int_{-\infty}^{+\infty}e^{itx}f(x)dx = \mathcal{F}(-t)
$$
由(2.3.4)式，我们知道将两个变量卷积只需要将它们的傅里叶变换的函数相乘再变回即可，又根据这里的公式，我们就可以得出，**最后卷积得到的随机变量它的特征函数其实就等于所有参与卷积的随机变量的特征函数的乘积。**

当我们尝试把等式左边泰勒展开，就可以看到特征函数与这个随机变量的矩的关系
$$
E[e^{-itX}] = \sum\limits_{n=0}^{\infty}E[\frac{(-itX)^n}{n!}] = \sum\limits_{n=0}^{\infty}\frac{(-it)^n}{n!}E(X^n)
$$
特征函数可以被随机变量的矩表示！这其实也意味着，如果一个随机变量存在n阶矩的话它也可以被矩表示出来。如果我们只取前三项
$$
E[e^{-itX}] \approx 1 - itE[X] - \frac{t^2}{2}E[X^2]  \\
\approx 1 - itE[X] - \frac{t^2}{2}(D(X) + E^2[X]) \tag{2.3.9}
$$


### 定理证明

这里并不会给出很严格的证明，而是窥探定理背后的真理

设总体$X$服从概率密度函数为$f$的分布，且满足$E(X) = \mu  $ $D(X) = \sigma^2$  

标准化变量$Z_i = \frac{X_i-\mu}{\sigma}$ 所以$E(Z_i) = 0$  $D(Z_i) = 1$

由(2.3.9)可知
$$
\phi_{Z_i}(t) = E[e^{-itZ_i}] \approx 1 - \frac{t^2}{2}
$$
考虑$S_n =\frac{1}{\sqrt{n}} \sum\limits_{i=1}^{n}Z_i$ , $E[S_n] = 0$ $D(S_n) = 1$

所以
$$
\phi_{S_n}(t) = \phi^n_{\frac{Z}{\sqrt{n}}}(t) \approx (1-\frac{t^2}{2n})^n
$$
极限情况
$$
\lim_{n \to \infty}\phi_{S_n}(t) = \lim_{n \to \infty}(1-\frac{t^2}{2n})^n = e^{-\frac{t^2}{2}}
$$


再将$\phi_{S_n}(t)$ 进行傅里叶逆变换就可以得到$S_n$的pdf
$$
f_Y(y) = \int_{-\infty}^{+\infty}e^{-itx}\phi_{S_n}(t)dt =\int_{-\infty}^{+\infty}e^{-itx-\frac{t^2}{2}}dt = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$
这里计算积分的时候需要先将指数部分配方，然后使用变量代换，变成一个二重积分计算

所以我们可以得出$S_n \sim N(0, 1)$ 中心极限定理也就得证了。



### 分析

我们在证明过程中并没有要求随机变量服从什么具体的分布，而只要求它的期望和方差存在，我们就可以使用高斯分布来近似它。这就很好的说明了无论什么分布，只要对自己卷积足够次数就可以近似成一个高斯分布。

在我们日常生活中很多东西都是叠加产生的，尽管在一开始的时候它可能服从一些奇奇怪怪的分布，但是只要叠加的够多，就会变成一个高斯分布，这也是为什么高斯分布适用范围广的原因。



## 总结

### 特征函数

特征函数在处理卷积之所以厉害我感觉是因为它统一了变量，对于多个随机变量，它们的特征函数中的变量都是同一个复数，所以可以很好的化简，很有魅力。和降维打击一样，将低维的实数域函数映射到二维的复数域函数后，就可以很好的计算，这很符合直觉。



### 随机变量

我们知道一个随机变量的pdf可以表示某个分布,而傅里叶变换又是一一映射的，所以随机变量的特征函数也会包含所有的信息，我们对特征函数进行泰勒展开以后，可以看到一个随机变量的矩也可以表示整个分布，只是矩可能会不存在。



### 高斯分布

我们现在来观察一个均值为0，方差为1的随机变量$X$,它的特征函数可以近似为: $1-\frac{t^2}{2}$

当t比较小的时候:
$$
1-\frac{t^2}{2} \approx e^{-\frac{t^2}{2}}
$$
而这是正态分布的特征函数，所以在这个小范围内可以使用正态分布来估计任何均值为0，方差为1的随机变量的值，这也解答了我一开始的疑惑。当然这里肯定会又误差的存在，这也只是提供一种解释的方法而已。



### 应用

高斯分布经常用来

1. 估计不可计算的误差，例如：测量误差
2. 机器学习中的判别分析，PCA等等
3. 估计多个独立同分布的随机变量的卷积
4. $\cdots$



希望我的描述可以给你带来新的理解，但同时请注意:

**本文只是提供一种感受中心极限定理背后的逻辑的思路，很多地方并不严谨，甚至有错误**

例如：泰勒展开和傅里叶变换都需要一定条件、函数的定义域模糊不清、复变函数积分等等

但我的本意也只是建立一个直观的理解，所以并没有过多提及这些条件。

